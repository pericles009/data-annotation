{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xETbDF4E9aXQ"
      },
      "outputs": [],
      "source": [
        "# --- INSTALLATION & SETUP ---\n",
        "# Install ultralytics if running in a new environment\n",
        "# !pip install ultralytics\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow # Colab specific\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "from glob import glob\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- GLOBAL CONFIGURATION ---\n",
        "# Base path for the project - CHANGE THIS if you are cloning the repo\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/Projeto_CNN/my_dataset'\n",
        "train_img_dir = os.path.join(base_path, 'train/images')\n",
        "train_lbl_dir = os.path.join(base_path, 'train/labels')\n",
        "val_img_dir = os.path.join(base_path, 'val/images')\n",
        "val_lbl_dir = os.path.join(base_path, 'val/labels')\n",
        "\n",
        "print(f\"Project Base Directory: {base_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: CREATE DATASET CONFIG (YAML) ---\n",
        "# This defines the classes and paths for YOLO\n",
        "\n",
        "yaml_content = f\"\"\"\n",
        "path: \"{base_path}\" # Points to root folder\n",
        "train: train/images\n",
        "val: val/images\n",
        "\n",
        "nc: 3\n",
        "names: ['Person', 'Ball','Equipment']\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = os.path.join(base_path, 'data.yaml')\n",
        "with open(yaml_path, 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(f\"Data.yaml created successfully at: {yaml_path}\")"
      ],
      "metadata": {
        "id": "_1wo6CfE9fyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2: DATA AUGMENTATION (OFFLINE) ---\n",
        "# Since the dataset is small, we physically generate new images\n",
        "# by flipping horizontally and changing contrast.\n",
        "\n",
        "print(f\"Generating variations for images in: {train_img_dir}\")\n",
        "\n",
        "arquivos = [f for f in os.listdir(train_img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "count_created = 0\n",
        "\n",
        "for arq in arquivos:\n",
        "    # 1. Load Original Image and Label\n",
        "    img_path = os.path.join(train_img_dir, arq)\n",
        "    txt_path = os.path.join(train_lbl_dir, os.path.splitext(arq)[0] + '.txt')\n",
        "\n",
        "    if not os.path.exists(txt_path):\n",
        "        continue\n",
        "\n",
        "    img_original = cv2.imread(img_path)\n",
        "\n",
        "    with open(txt_path, 'r') as f:\n",
        "        linhas = f.readlines()\n",
        "\n",
        "    # TECHNIQUE A: HORIZONTAL FLIP\n",
        "    img_flip = cv2.flip(img_original, 1)\n",
        "    linhas_flip = []\n",
        "    for linha in linhas:\n",
        "        parts = linha.strip().split()\n",
        "        cls = parts[0]\n",
        "        x, y, w, h = map(float, parts[1:])\n",
        "\n",
        "        # Recalculate X coordinate: new_x = 1.0 - old_x\n",
        "        new_x = 1.0 - x\n",
        "        linhas_flip.append(f\"{cls} {new_x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "    # Save Flip\n",
        "    nome_flip = os.path.splitext(arq)[0] + '_flip'\n",
        "    cv2.imwrite(os.path.join(train_img_dir, nome_flip + '.jpg'), img_flip)\n",
        "    with open(os.path.join(train_lbl_dir, nome_flip + '.txt'), 'w') as f:\n",
        "        f.writelines(linhas_flip)\n",
        "    count_created += 1\n",
        "\n",
        "    # TECHNIQUE B: HIGH CONTRAST\n",
        "    img_contrast = cv2.convertScaleAbs(img_original, alpha=1.3, beta=10)\n",
        "    nome_contrast = os.path.splitext(arq)[0] + '_contrast'\n",
        "    cv2.imwrite(os.path.join(train_img_dir, nome_contrast + '.jpg'), img_contrast)\n",
        "    with open(os.path.join(train_lbl_dir, nome_contrast + '.txt'), 'w') as f:\n",
        "        f.writelines(linhas) # Same labels\n",
        "    count_created += 1\n",
        "\n",
        "print(f\"Data Augmentation Finished! {count_created} new files created.\")"
      ],
      "metadata": {
        "id": "zgtFDFNS9ii7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: DATASET SHUFFLE & SPLIT ---\n",
        "# Mixes generated data and re-splits into Train (80%) and Val (20%)\n",
        "# to ensure the model is evaluated on diverse data.\n",
        "\n",
        "# 1. Move everything to Train temporary\n",
        "print(\"Merging validation back to train for shuffling...\")\n",
        "val_images = glob(os.path.join(val_img_dir, '*.*'))\n",
        "for f in val_images:\n",
        "    shutil.move(f, train_img_dir)\n",
        "    lbl_name = os.path.basename(f).rsplit('.', 1)[0] + '.txt'\n",
        "    src_lbl = os.path.join(val_lbl_dir, lbl_name)\n",
        "    if os.path.exists(src_lbl):\n",
        "        shutil.move(src_lbl, train_lbl_dir)\n",
        "\n",
        "# 2. Shuffle\n",
        "all_images = glob(os.path.join(train_img_dir, '*.*'))\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# 3. Split 20% for Validation\n",
        "split_idx = int(len(all_images) * 0.2)\n",
        "val_files = all_images[:split_idx]\n",
        "\n",
        "print(f\"Total images: {len(all_images)}. Moving {len(val_files)} to validation...\")\n",
        "\n",
        "for f in val_files:\n",
        "    shutil.move(f, val_img_dir)\n",
        "    lbl_name = os.path.basename(f).rsplit('.', 1)[0] + '.txt'\n",
        "    src_lbl = os.path.join(train_lbl_dir, lbl_name)\n",
        "    if os.path.exists(src_lbl):\n",
        "        shutil.move(src_lbl, val_lbl_dir)\n",
        "\n",
        "print(\"Dataset re-split completed.\")"
      ],
      "metadata": {
        "id": "eRWrm0Zt9k_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: MODEL TRAINING ---\n",
        "# Load pretrained YOLOv8 nano model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train with aggressive online augmentation settings\n",
        "results = model.train(\n",
        "    data=yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    patience=15,          # Early Stopping\n",
        "    batch=8,              # Low batch for small datasets\n",
        "\n",
        "    # Online Augmentation Parameters (Hyperparameters)\n",
        "    augment=True,\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    degrees=15.0, translate=0.1, scale=0.5,\n",
        "    fliplr=0.5, mosaic=1.0, mixup=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "SnNeRzUL9nnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 5: INFERENCE / TESTING ---\n",
        "\n",
        "# Load the best model from the latest training run\n",
        "# Note: Adjust 'train7' to your actual folder name if needed\n",
        "best_model_path = '/content/runs/detect/train/weights/best.pt'\n",
        "model_trained = YOLO(best_model_path)\n",
        "\n",
        "# Define test image path\n",
        "test_image = os.path.join(val_img_dir, 'Captura de tela 2026-01-04 140826.png')\n",
        "\n",
        "print(f\"Testing model on: {test_image}\")\n",
        "\n",
        "# Predict with adjusted Confidence and IOU (to remove duplicates)\n",
        "results = model_trained.predict(test_image, conf=0.05, iou=0.4)\n",
        "\n",
        "# Display results\n",
        "for result in results:\n",
        "    im_array = result.plot()\n",
        "    cv2_imshow(im_array)"
      ],
      "metadata": {
        "id": "QKsebaI09qfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}